{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "616a2b4e-c9e9-4938-bc4b-af5efccf863c",
   "metadata": {},
   "source": [
    "Exploratory script for relevance analasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1fc0f39-e863-42e0-bf50-3f1dc34bc385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/madelinemiller/Desktop/data_literacy/geonews_femicide/source/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "#install libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tueplots\n",
    "\n",
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e8090f-ff30-49f4-9808-fa7db8eace97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set source and output paths\n",
    "source_path = '../../data/'\n",
    "csv_output_path = '../../data/processed/'\n",
    "figure_output_path = '../../paper/figures/'\n",
    "\n",
    "#upload manually tagged articles with json data\n",
    "df_tag = pd.read_csv(f'{source_path}processed/manual-tag_all_parsedson.csv') \n",
    "#upload keyword data\n",
    "df_key = pd.read_csv(f'{source_path}manual_tag/femicide_keywords.csv')\n",
    "#upload top 25 data\n",
    "df_25 = pd.read_csv(f'{source_path}processed/7-14_22-24_26-27_29-32_2017-2023_top25.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f944c1-e315-4e24-9227-18bd3b3b8373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to fileter for German NUTS codes and join them into a single string per article id\n",
    "def nuts_filter(df):\n",
    "    #Ensure NUTS is a string and handle missing values\n",
    "    df['NUTS'] = df['NUTS'].fillna('').astype(str)\n",
    "\n",
    "    # Group by 'id' and aggregate\n",
    "    # Will only keep codes starting with 'DE' (German NUTS)\n",
    "    df_nuts_combined = df.groupby('id').agg({\n",
    "        'url': 'first',\n",
    "        'hostname': 'first',\n",
    "        'date': 'first',\n",
    "        'date_crawled': 'first',\n",
    "        'loc_normal': lambda x: ', '.join(sorted(set(code for code in x))),\n",
    "        'NUTS': lambda x: ', '.join(sorted(set(code for code in x if code.startswith('DE')))),\n",
    "        'cos_dist': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Remove rows where no German NUTS codes were found after filtering\n",
    "    df_nuts_combined = df_nuts_combined[df_nuts_combined['NUTS'] != ''].copy()\n",
    "\n",
    "    return df_nuts_combined\n",
    "\n",
    "def date_filter(df, startYear, endYear): \n",
    "    #Convert the date column to datetime objects\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "    # Filter for dates\n",
    "    # use .copy() to avoid SettingWithCopy warnings \n",
    "    df_dates = df[(df['date'].dt.year >= startYear) & (df['date'].dt.year <= endYear)].copy()\n",
    "\n",
    "    return df_dates\n",
    "\n",
    "def load_csv(name, path, storage_dict):\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        #add to df dictionary\n",
    "        storage_dict[name] = df \n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: File not found at {path}\")\n",
    "\n",
    "def rank_csv(df):\n",
    "    # Calculate rank \n",
    "    df['cosine_rank'] = df['cos_dist'].rank(method='min', ascending=True)\n",
    "    df_ranked = df.sort_values(by=\"cos_dist\", ascending=True)\n",
    "    return df_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c83770a-f95a-45b8-a87c-557e53574e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload raw query data, filter to create processed datasets\n",
    "startYear = 2017\n",
    "endYear = 2023\n",
    "\n",
    "#create dictionaries for data frames\n",
    "dfs_raw = {}\n",
    "dfs_processed = {}\n",
    "\n",
    "#list of query names\n",
    "name_list = [\n",
    "    \"7_police-report-gender-motivated_EN\",\n",
    "    \"8_police-report-gender-motivated_DE\",\n",
    "    \"9_woman-girl-killed_EN\",\n",
    "    \"10_woman-girl-killed_DE\",\n",
    "    \"11_murder-woman-victim_EN\",\n",
    "    \"12_murder-woman-victim_DE\",\n",
    "    \"13_victim-woman-long_EN\",\n",
    "    \"14_victim-woman-long_DE\",\n",
    "    \"15_newsart_report_fem_EN\",\n",
    "    \"16_newsart_report_fem_DE\",\n",
    "    \"17_newsart_report_case_EN\",\n",
    "    \"18_newsart_report_case_DE\",\n",
    "    \"19_euphemistic_bluttat_DE\",\n",
    "    \"20_euphemistic_Beziehungsdrama_DE\",\n",
    "    \"21_euphemistic_EhetragÃ¶die_DE\",\n",
    "    \"22_femicide_Femizid_DE\",\n",
    "    \"23_femicide_Frauenmord_DE\",\n",
    "    \"24_femicide_Feminizid_DE\",\n",
    "    \"25_euphemistic_Ehrenmord_DE\",\n",
    "    \"26_femicide_Femicide_EN\",\n",
    "    \"27_femicide_femicide_EN\",\n",
    "    \"28_heat-pumps_EN\",\n",
    "    \"29_woman-was-murdered_DE\",\n",
    "    \"30_woman-was-killed_DE\",\n",
    "    \"31_murder-woman-girl_DE\",\n",
    "    \"32_homicide-female_DE\"\n",
    "] \n",
    "\n",
    "# Load all data\n",
    "for name in name_list:\n",
    "    file_path = f\"{source_path}repository_queries/500000_{name}.csv\"\n",
    "    load_csv(name, file_path, dfs_raw)\n",
    "\n",
    "for name, df in dfs_raw.items():\n",
    "    #filter to set dates\n",
    "    df_date = date_filter(df, startYear, endYear)\n",
    "    #combine all NUTS into one entry per unique article id\n",
    "    #filter to only entries that contain German NUTS\n",
    "    df_date_nuts = nuts_filter(df_date)\n",
    "    #add cosine ranking\n",
    "    df_date_nuts_rank = rank_csv(df_date_nuts)\n",
    "    #store in df dictionary\n",
    "    dfs_processed[name] = df_date_nuts_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32b576c8-a990-4ee1-8eb7-d158dc16bc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw shape: (1236694, 13), processed shape: (337690, 9)\n",
      "raw shape: (1499468, 13), processed shape: (339112, 9)\n",
      "raw shape: (1263367, 13), processed shape: (280984, 9)\n",
      "raw shape: (1127514, 13), processed shape: (241896, 9)\n",
      "raw shape: (1053118, 13), processed shape: (293905, 9)\n",
      "raw shape: (1144034, 13), processed shape: (286227, 9)\n",
      "raw shape: (1027935, 13), processed shape: (296778, 9)\n",
      "raw shape: (1298913, 13), processed shape: (331433, 9)\n",
      "raw shape: (1034786, 13), processed shape: (201819, 9)\n",
      "raw shape: (1398456, 13), processed shape: (211654, 9)\n",
      "raw shape: (1390774, 13), processed shape: (268825, 9)\n",
      "raw shape: (1459069, 13), processed shape: (288038, 9)\n",
      "raw shape: (898140, 13), processed shape: (202836, 9)\n",
      "raw shape: (500388, 13), processed shape: (146979, 9)\n",
      "raw shape: (783290, 13), processed shape: (188263, 9)\n",
      "raw shape: (919470, 13), processed shape: (194384, 9)\n",
      "raw shape: (938998, 13), processed shape: (257966, 9)\n",
      "raw shape: (790872, 13), processed shape: (170359, 9)\n",
      "raw shape: (1027553, 13), processed shape: (212306, 9)\n",
      "raw shape: (812743, 13), processed shape: (199410, 9)\n",
      "raw shape: (830761, 13), processed shape: (198550, 9)\n",
      "raw shape: (486087, 13), processed shape: (180920, 9)\n",
      "raw shape: (1204266, 13), processed shape: (303107, 9)\n",
      "raw shape: (1237976, 13), processed shape: (307543, 9)\n",
      "raw shape: (1110503, 13), processed shape: (296439, 9)\n",
      "raw shape: (1143913, 13), processed shape: (364570, 9)\n",
      "Index(['id', 'url', 'hostname', 'date', 'hashed_id', 'date_crawled',\n",
      "       'loc_normal', 'latitude', 'longitude', 'NUTS', 'query_string',\n",
      "       'query_name', 'cos_dist'],\n",
      "      dtype='object')\n",
      "Index(['id', 'url', 'hostname', 'date', 'date_crawled', 'loc_normal', 'NUTS',\n",
      "       'cos_dist', 'cosine_rank'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#print out shape of each processed dataframe\n",
    "for name, df in dfs_processed.items():\n",
    "    #print shape raw\n",
    "    rawshape = dfs_raw[name].shape\n",
    "    procshape = dfs_processed[name].shape\n",
    "    print(f'raw shape: {rawshape}, processed shape: {procshape}')\n",
    "\n",
    "print(dfs_raw['32_homicide-female_DE'].columns)\n",
    "print(dfs_processed['32_homicide-female_DE'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf3f558e-7a22-46fd-984c-60b30cf6be94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1191, 19)\n",
      "sample shape: (677, 19)\n",
      "all checked shape: (1028, 19)\n",
      "32 sample shape: (677, 9)\n",
      "32 all checked shape: (1011, 9)\n"
     ]
    }
   ],
   "source": [
    "#get subsets of sampled and checked articles\n",
    "\n",
    "#ids that were sampled and had a T/F outcome \n",
    "#filter out nan for 'query_32_cosine_bin' and 'woman_murdered'\n",
    "#select only id\n",
    "df_sampled = df_tag.dropna(subset=['query_32_cosine_bin', 'woman_murdered'])\n",
    "#get list of ids\n",
    "sampled_ids = df_sampled['id']\n",
    "#filter raw dataset to just those ids\n",
    "df_32_sampled = dfs_processed[\"32_homicide-female_DE\"][dfs_processed[\"32_homicide-female_DE\"]['id'].isin(sampled_ids)].copy()\n",
    "\n",
    "#all ids that were manualy checked that had a T/F outcome\n",
    "#filter out nan for 'woman_murdered'\n",
    "df_checked = df_tag[df_tag['woman_murdered'].notna()]\n",
    "#get list of ids\n",
    "checked_ids = df_checked['id']\n",
    "#filter raw dataset to just those ids\n",
    "df_32_checked = dfs_processed[\"32_homicide-female_DE\"][dfs_processed[\"32_homicide-female_DE\"]['id'].isin(checked_ids)].copy()\n",
    "\n",
    "\n",
    "# Verify the result\n",
    "print(f\"Original shape: {df_tag.shape}\")\n",
    "print(f\"sample shape: {df_sampled.shape}\")\n",
    "print(f\"all checked shape: {df_checked.shape}\")\n",
    "print(f\"32 sample shape: {df_32_sampled.shape}\")\n",
    "print(f\"32 all checked shape: {df_32_checked.shape}\") \n",
    "#less than all checked because some checked articles were not included in q 32 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98448313-a1fe-4e78-9cc5-1eaa147e5e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT 32 all checked shape: (17, 19)\n",
      "15     False\n",
      "16     False\n",
      "86     False\n",
      "95     False\n",
      "97     False\n",
      "100    False\n",
      "101    False\n",
      "104    False\n",
      "107    False\n",
      "111    False\n",
      "115    False\n",
      "124    False\n",
      "125    False\n",
      "129    False\n",
      "130    False\n",
      "213    False\n",
      "215    False\n",
      "Name: woman_murdered, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#filter to only articles not in the q32 results (should be 14)\n",
    "df_32_ids = df_32_checked['id']\n",
    "checked_ids_notq32 = df_checked[df_checked['id'].isin(df_32_ids)==False].copy()\n",
    "print(f\"NOT 32 all checked shape: {checked_ids_notq32.shape}\") \n",
    "\n",
    "print(checked_ids_notq32['woman_murdered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05acd56d-4aa6-48be-9202-2e2157ff5517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q32 articles with cos_dist > 0.23 that were relevant: 15\n",
      "Q32 articles with cos_dist > 0.23 that were NOT relevant: 10\n",
      "Q32 articles with cos_dist > 0.23 that were not able to be verified: 6\n",
      "\n",
      "Total Q32 articles with cos_dist > 0.23: 31\n"
     ]
    }
   ],
   "source": [
    "#how many with cosine distance over .23 for Q32 were 1. relevant and 2. in top 25 of another query\n",
    "#add 'woman_murdered' relevance from df_tag to top_25\n",
    "# Add 'woman_murdered' relevance from df_tag to top_25 (don't do it if it's already done)\n",
    "\n",
    "df_25_tag = df_25\n",
    "\n",
    "if 'woman_murdered' not in df_25_tag.columns:\n",
    "    df_25_tag = df_25_tag.merge(\n",
    "        df_tag[['id', 'woman_murdered']], \n",
    "        on='id', \n",
    "        how='left'\n",
    "    ).copy()\n",
    "\n",
    "# Filter to Q32 articles with cosine distance > 0.23\n",
    "q32_highdist = df_25_tag[\n",
    "    (df_25_tag['cos_dist_32_homicide-female_DE'] > 0.23)\n",
    "].copy()\n",
    "\n",
    "q32_highdist.head()\n",
    "\n",
    "# How many were relevant?\n",
    "relevant_count = q32_highdist['woman_murdered'].sum()\n",
    "print(f\"Q32 articles with cos_dist > 0.23 that were relevant: {relevant_count}\")\n",
    "\n",
    "# How many were NOT relevant?\n",
    "not_relevant_count = (q32_highdist['woman_murdered'] == 0).sum()\n",
    "print(f\"Q32 articles with cos_dist > 0.23 that were NOT relevant: {not_relevant_count}\")\n",
    "\n",
    "# How many were not useable (NaN)?\n",
    "nan_count = q32_highdist['woman_murdered'].isna().sum()\n",
    "print(f\"Q32 articles with cos_dist > 0.23 that were not able to be verified: {nan_count}\")\n",
    "\n",
    "# Total\n",
    "print(f\"\\nTotal Q32 articles with cos_dist > 0.23: {len(q32_highdist)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edcd248b-59ae-4a2b-a82c-b1ba735baf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q32 high distance articles also in top 25 of another query: 15\n",
      "Out of 15 total Q32 high distance articles\n"
     ]
    }
   ],
   "source": [
    "#how many relevant top 25 are not in Q32?\n",
    "q32_highdist_rel = q32_highdist[q32_highdist['woman_murdered'] == True]\n",
    "\n",
    "# Get cosine rank for all queries except Q32\n",
    "rank_columns = [col for col in q32_highdist_rel.columns if col.startswith('cos_rank_') and 'cos_rank_32_homicide-female_DE' not in col]\n",
    "\n",
    "# Check how many Q32 high distance articles have rank <= 25 in other queries\n",
    "articles_top25_in_other_queries = []\n",
    "\n",
    "for idx, row in q32_highdist_rel.iterrows():\n",
    "    article_id = row['id']\n",
    "    \n",
    "    # Check if this article appears in top 25 of any other query\n",
    "    for rank_col in rank_columns:\n",
    "        if pd.notna(row[rank_col]) and row[rank_col] <= 25:\n",
    "            articles_top25_in_other_queries.append(article_id)\n",
    "            break  # Count each article only once\n",
    "\n",
    "unique_count = len(set(articles_top25_in_other_queries))\n",
    "print(f\"Q32 high distance articles also in top 25 of another query: {unique_count}\")\n",
    "print(f\"Out of {len(q32_highdist_rel)} total Q32 high distance articles\")\n",
    "\n",
    "#filter raw dataset to just those ids\n",
    "df_highcos_top25 = q32_highdist_rel[q32_highdist_rel['id'].isin(articles_top25_in_other_queries)].copy()\n",
    "\n",
    "#return csv\n",
    "df_highcos_top25.to_csv(f'{csv_output_path}top25_notq32.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0ca25d9-d431-4d93-83f7-b55c081f6c97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_32' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#what is the distribution of the distances of all articles? \u001b[39;00m\n\u001b[32m      2\u001b[39m plt.figure(figsize=(\u001b[32m5\u001b[39m, \u001b[32m3\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m sns.histplot(\u001b[43mdf_32\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mcos_dist\u001b[39m\u001b[33m'\u001b[39m], kde=\u001b[38;5;28;01mTrue\u001b[39;00m, color=\u001b[33m'\u001b[39m\u001b[33mred\u001b[39m\u001b[33m'\u001b[39m, bins=\u001b[32m30\u001b[39m)\n\u001b[32m      5\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mDistribution of all q32 Cosine Distance (cos_dist)\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mCosine Distance\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_32' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#what is the distribution of the distances of all articles? \n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.histplot(df_32['cos_dist'], kde=True, color='red', bins=30)\n",
    "    \n",
    "plt.title('Distribution of all q32 Cosine Distance (cos_dist)')\n",
    "plt.xlabel('Cosine Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207af5ce-1968-45d4-9116-7140484833db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_32_sampled['cos_dist'].head())\n",
    "#what is the distribution of the distances of sampled articles?\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.histplot(data=df_32_sampled['cos_dist'], kde=True, color='red', bins=30)\n",
    "    \n",
    "plt.title('Distribution of sampled Cosine Distance (cos_dist)')\n",
    "plt.xlabel('Cosine Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde50f69-06d6-4b92-b88c-4ee75a81365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is the distribution of the distances of all checked articles?\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.histplot(data=df_32_checked['cos_dist'], kde=True, color='red', bins=30)\n",
    "    \n",
    "plt.title('Distribution of all checked Cosine Distance (cos_dist)')\n",
    "plt.xlabel('Cosine Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f0d10-505f-406c-b464-1ff6840242ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the query, how many relavant/irrelavant articles are included in each cosine bin?\n",
    "#create a list of bins\n",
    "cos_bin = df_tag['query_32_cosine_bin'].unique()\n",
    "print(len(cos_bin))\n",
    "print(cos_bin)\n",
    "\n",
    "# Count relevant and not relevant per bin\n",
    "bin_counts = df_sampled.groupby(['query_32_cosine_bin', 'woman_murdered']).size().reset_index(name='count')\n",
    "\n",
    "print(bin_counts)\n",
    "\n",
    "# sort bins numerically\n",
    "bin_order = ['(0.16, 0.18]', '(0.18, 0.2]', '(0.2, 0.22]', '(0.22, 0.24]', '(0.24, 0.26]', '(0.26, 0.28]']\n",
    "bin_counts['query_32_cosine_bin'] = pd.Categorical(bin_counts['query_32_cosine_bin'], categories=bin_order, ordered=True)\n",
    "bin_counts = bin_counts.sort_values('query_32_cosine_bin')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.barplot(\n",
    "    data=bin_counts,\n",
    "    x='query_32_cosine_bin',\n",
    "    y='count',\n",
    "    hue='woman_murdered'\n",
    ")\n",
    "plt.title('Relevant vs. Not Relevant Samples per Cosine Bin')\n",
    "plt.xlabel('Cosine Similarity Bin')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Relevance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024b25fb-9558-48f4-a9fb-74929337e497",
   "metadata": {},
   "outputs": [],
   "source": [
    " df_32_checked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee34eb2a-dbbe-4014-9083-6bc815e262a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_bin_check(df, df_tag): \n",
    "    # Filter to only t/f results\n",
    "    # Filter out nan for 'woman_murdered' in tagged results\n",
    "    df_checked_tag = df_tag[df_tag['woman_murdered'].notna()].copy()\n",
    "    \n",
    "    # Get list of ids\n",
    "    checked_ids = df_checked_tag['id']\n",
    "    \n",
    "    # Filter dataset to just those ids\n",
    "    df_query = df[df['id'].isin(checked_ids)].copy()  # Changed from df_query to df\n",
    "    \n",
    "    # Sort all checked into bins (add cosine bin row)\n",
    "    df_query['all_cosine_bin'] = pd.cut(\n",
    "        df_query['cos_dist'],\n",
    "        bins=[0.16, 0.18, 0.20, 0.22, 0.24, 0.26, 0.28, np.inf],\n",
    "        labels=['(0.16, 0.18]', '(0.18, 0.2]', '(0.2, 0.22]', \n",
    "                '(0.22, 0.24]', '(0.24, 0.26]', '(0.26, 0.28]', '(0.28+)']\n",
    "    )\n",
    "    \n",
    "    # Merge the bin information back to df_checked_tag\n",
    "    df_checked_tag = df_checked_tag.merge(\n",
    "        df_query[['id', 'all_cosine_bin']], \n",
    "        on='id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Check result\n",
    "    print(df_checked_tag['all_cosine_bin'].value_counts())\n",
    "    \n",
    "    # Count relevant and not relevant per bin\n",
    "    bin_counts = df_checked_tag.groupby(['all_cosine_bin', 'woman_murdered'], observed=True).size().reset_index(name='count')\n",
    "    \n",
    "    print(bin_counts)\n",
    "    \n",
    "    # Sort bins numerically\n",
    "    bin_order = ['(0.16, 0.18]', '(0.18, 0.2]', '(0.2, 0.22]', '(0.22, 0.24]', '(0.24, 0.26]', '(0.26, 0.28]', '(0.28+)']\n",
    "    bin_counts['all_cosine_bin'] = pd.Categorical(bin_counts['all_cosine_bin'], categories=bin_order, ordered=True)\n",
    "    bin_counts = bin_counts.sort_values('all_cosine_bin')\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.barplot(\n",
    "        data=bin_counts,\n",
    "        x='all_cosine_bin',\n",
    "        y='count',\n",
    "        hue='woman_murdered'\n",
    "    )\n",
    "    plt.title('Relevant vs. Not Relevant Samples per Cosine Bin')\n",
    "    plt.xlabel('Cosine Similarity Bin')\n",
    "    plt.ylabel('Number of Articles')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Relevance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9720bf6d-0139-4e57-875f-47ed8d095bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_bin_check(dfs_processed['32_homicide-female_DE'],df_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f868da-3adb-40a2-a1e9-df1a2af05105",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_bin_check(df_32_sampled,df_tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geonews_femicide)",
   "language": "python",
   "name": "geonews_femicide"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
